# 朴素贝叶斯算法

#### 贝叶斯思想？

朴素贝叶斯分类是一种十分简单的分类算法，一个含有贝叶斯思想的例子可以这样。你在路上看到一个黑人且比较高，你十有八九猜他是从非洲来的。

因为在没有其他可用信息的前提下，一般来说大部分非洲人符合这种特征，所以你会选择最大概率是非洲人，这种思想就是贝叶斯思想。

#### 一个非常简单的例子

![机器学习：生动理解朴素贝叶斯算法](http://p3.pstatp.com/large/3b0400012c941c84b56a)

简单来说，你晚起床迟到的后验概率是：

![机器学习：生动理解朴素贝叶斯算法](http://p1.pstatp.com/large/3b0400012c96c5de2a7c)

正规来写：

![机器学习：生动理解朴素贝叶斯算法](http://p1.pstatp.com/large/3b03000136173f33ba73)

#### 算法流程

**好了，我们知道后验概率由条件概率、先验概率和现象概率计算得来。**

那么根据这个表(分类预测是否健康的人的例子)来解释这些名词：

![机器学习：生动理解朴素贝叶斯算法](http://p3.pstatp.com/large/3b0500012241fec9e700)

**1.条件概率**

由于朴素贝叶斯有“朴素”的前提假设，即特征两两独立同分布。所以条件概率可以用全概率公式写成以下形式：

![机器学习：生动理解朴素贝叶斯算法](http://p3.pstatp.com/large/3b070000faa0e5f0d88d)

以上公式简单来说就是在给定某个类别下，观察到出现现象x的概率。在特征向量中的每个特点的概率我们都可以通过极大似然估计(maximum-likelihood estimate)来求得，也就是简单地求某个特征在某个类别中的频率，公式如下：

![机器学习：生动理解朴素贝叶斯算法](http://p1.pstatp.com/large/3b0500012242412c2bb4)

其中，分子代表所有属于类别wj的样本中，特征xi出现的次数；分母代表属于类别wj的样本中，所有特征出现的次数。

现在我们求P(old,smoke|is_healthy)的概率，通过上述公式求得结果如下：

![机器学习：生动理解朴素贝叶斯算法](http://p3.pstatp.com/large/3b020004327855ebc204)

**2.先验概率**

先验概率其实很简单，例如上面例子是健康的概率为1/2，不健康的概率为1/2，用公式表达如下：

![机器学习：生动理解朴素贝叶斯算法](http://p9.pstatp.com/large/3b0600011ecff503ec9c)

其中，分子代表属于类wj的样本数，分母代表所有样本数。

需要注意的是，有些数据集中对应的先验概率实际上会有偏差，例如一个数据集中有10个人，中500w的有5个人，这时候就要考虑下这个数据集是否存在分布偏差，需要自设先验概率。

**3.现象概率**

现象概率是独立于类别之外的，是在所有样本中该特征值的概率，例如上面抽烟的概率是P (smoke) = 3/4，跟属于哪一类没有关系。

#### 分类预测

**通过学到每个特征值在该类下的概率后，给定未分类实例有特征X，就可以通过上述计算过程进行计算，得到该实例属于各类的后验概率p(y=c_k|X)，然后取各类的后验概率的最大值即可。**

如果有新数据要预测人是否健康，那么可以得到公式：

![机器学习：生动理解朴素贝叶斯算法](http://p3.pstatp.com/large/3b0500012244435ab2dc)

![机器学习：生动理解朴素贝叶斯算法](http://p9.pstatp.com/large/3b05000122454132e1a8)

通过上述计算公式后，比较两者的大小，选择最大值即可。

#### 拉普拉斯平滑(Additive Smoothing)

假设我们要计算P(old|healty)的概率，会发现这个条件概率等于0，那么由于全概率公式是连乘的情况，会导致后验概率等于0。为了避免0概率的发生，我们可以加上平滑项，把上面条件概率的公式 改为下面的形式：

![机器学习：生动理解朴素贝叶斯算法](http://p3.pstatp.com/large/3b0600011ed0d0bd09a0)

其中a是附加的平滑项参数，a<1叫做Lidstone smoothing，a=1叫做Laplace smoothing。

#### 总结

**朴素：特征两两之间独立同分布假设(i.i.d)；**

**贝叶斯：基于贝叶斯定理。**

根据贝叶斯定理，对一个分类问题，给定样本特征X，样本属于类别y的概率是：

![机器学习：生动理解朴素贝叶斯算法](http://p3.pstatp.com/large/3b0500012246217f9e36)

这里X是对应的特征项，将特征维度设为M，因为特征两两之间独立同分布，根据全概率公式展开，上述公式变为：

![机器学习：生动理解朴素贝叶斯算法](http://p1.pstatp.com/large/3b0400012c9ce23e433e)

通过上述公式，只要计算出每一个特征Xi在每一类的条件概率就行了，每一类的先验概率可以在训练集中计算可得，同样可以计算得出每一类上的条件独立的特征对应的条件概率总和。