## 机器学习：聊聊贝叶斯推断的衍生思想

#### 又是贝叶斯？

之前在写文章时有简单聊聊朴素贝叶斯算法的计算方式，回到那个简单的例子，你在路上看到一个黑人且比较高，你会十有八九猜他是从非洲来的。

为什么呢？因为在没有其他可用信息的前提下，一般来说大部分非洲人符合这种特征，所以你会选择最大概率是非洲人，这种思想就是贝叶斯思想。

#### 一个很有名的公式

![机器学习：聊聊贝叶斯推断的衍生思想](http://p3.pstatp.com/large/3c750002cebdc0a21b4c)

如果大家上过概率论肯定对此有印象，该公式就是贝叶斯定理，它的创立者就是托马斯·贝叶斯。**该公式大概讲述这么一个道理，现在有那么一个事件A存在，我们对事件A发生的概率有自己的主观判定，为P(A)。在事件B发生后，我们认识到，事件A发生的概率由于事件B的发生导致了变化，此时事件A变化后的概率为P(A|B)。**

#### 举个简单的例子

![机器学习：聊聊贝叶斯推断的衍生思想](http://p1.pstatp.com/large/3c750002cf631697eca2)

简单来说，你晚起床迟到的后验概率是：

![机器学习：聊聊贝叶斯推断的衍生思想](http://p1.pstatp.com/large/3c7800029ff76383a7a5)

正规来写：

![机器学习：聊聊贝叶斯推断的衍生思想](http://p3.pstatp.com/large/3c770002c516669e096f)

#### 贝叶斯推断

贝叶斯思想在更新概率就是通过不断得到新的证据来更新自己的信念，这种概率思维方式被称为贝叶斯推断。

假设，现在有一个刚写好但没测过的代码，一开始我们主观认为自己写的代码bug应该在80%的几率可以通过编译，如果编译发生错误，则实际概率比80%要低，通过不断的依靠数据来刷新概率（信念）。

**事实上，我们会随着新的证据不断更新之前的信念，但很少做出绝对的判断，除非所有其他的可能性都被一一排除。**

#### 贝叶斯思维

**频率派**

对频率派而言，概率是事件在长时间内所发生的频率。即一枚质地均匀的硬币随机抛了3次，3次都朝上，则说明向上的概率是100%。但是实际上明显不是如此，一枚质地均匀的硬币每次抛出的正反概率各50%。事实上这受到数据样本的影响，如果数据足够大，在通常情况下可以通过频率验证去验证概率，即大数定律。

**贝叶斯派**

对贝叶斯派而言，概率是对事件发生的信心。对已发生的事件如抛硬币，可以多次尝试得到结论，此时频率可用。但对新任的总统选举则不能用频率解决，但可以用先验概率说明人们对该候选人当上总统的信心（概率）是多少。

**先验概率和后验概率**

先验概率是我们对事件A发生的信念，记为P(A)。

后验概率是随着证据的发生（新数据迭代）需要对事件A的信念发生改变，可以增加，减少或者不变，此时根据证据发生后所更新的对事件A的信念称作P(A|X)。

#### 加入“证据”

**当我们添加更多的证据后，初始的信念会不断被“洗刷”直到你对事件的主观信念逼近客观信念为止。**

让N表示我们拥有的证据的数量，如果N趋于无穷大，那么贝叶斯的结果通常和频率派的结果一致。

对于较小的N，通过引入先验概率和返回概率结果（而不是某个固定值），保留了其不确定性，这种不确定性正是小数据集的不稳定性的反应。

Andrew Gelman说过：样本从来都不是足够大的，如果N大小不足以进行足够精确的估计，你需要获得更多的数据。但当N足够大，你已经开始划分更小的数据集进行更深层次问题的探究。