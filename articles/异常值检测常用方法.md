## 异常值检测常用方法

#### 异常值存在的原因

(1)数据来源于不同的类：某个数据对象可能不同于其他数据对象(即异常)，因为它术语一个不同的类型或类。

Hawkins 的离群点定义：离群点是一个观测值，它与其他观测值的差别如此之大，以至于怀疑它是由不同的机制产生的。

(2)自然变异：许多数据集可以用一个统计分布建模，如正态(高斯)分布建模，其中数据对象的概率随对象到分布中心距离的增加而急剧减少。换言之，大部分数据对象靠近中心(平均对象)，数据对象显著地不同于这个平均对象的似然性很小。

(3)数据测量和收集误差：数据收集和测量过程中的误差是另一个异常源。剔除这类异常是数据预处理(尤其是数据清理)的关注点。

#### 异常处理

**1、简单统计量分析**

先对变量做一个描述性统计，进而查看哪些数据是不合理的，如箱型图分析，平均值，最大最小值分析，统计学上的3σ法则（若数据服从正太分布，在3σ原则下，异常值被定义为一组测定值中与平均值的偏差超过3倍标准差的值，因为在正态分布的假设下，距离平均值3σ之外的值出现的概率小于0.003）。

**(例如一维数据对应所有元素x1,x2..xn，求出对应的3σ，若x>3σ或x<3σ，则剔除 )**

标准化数值（Z-score）可用来帮助识别异常值。Z分数标准化后的数据服从正态分布。因此，应用Z分数可识别异常值。我们建议将Z分数低于-3或高于3的数据看成是异常值。这些数据的准确性要复查，以决定它是否属于该数据集。

**(例如一维数据对应所有元素x1,x2..xn，对应z-score =(x-mean)/std,若每个x的z-score>3或z-score<3，则剔除 )**

![一文读懂机器学习中数据集异常值常见的处理方法](http://p1.pstatp.com/large/433a00042bd97990479d)

**2、基于距离的方法**

通常可以在对象之间定义邻近性度量，并且许多移仓检测方法都基于邻近度。异常对象是那些远离大部分其他对象的对象，这一邻域的许多技术都基于距离，称作基于距离的离群点检测技术，代表算法：基于KNN的密度检测算法。

优点与缺点：

基于邻近度的方法一般需要O(m^2)时间。这对于大型数据集可能代价过高，尽管在低维情况下可以使用专门的算法来提高性能。**该方法对参数的选择也是敏感的。此外，它不能处理具有不同密度区域的数据集，因为它使用全局阈值，不能考虑这种密度的变化。**

**3、基于密度的离群点检测：**

从基于密度的观点来看，离群点是在低密度区域中的对象。基于密度的离群点检测与基于邻近度的离群点检测密切相关，因为密度通常用邻近度定义。一种常用的定义密度的方法是，定义密度为到k个最近邻的平均距离的倒数。如果该距离小，则密度高，反之亦然。

优点与缺点：

基于相对密度的离群点检测给出了对象是离群点程度的定量度量，并且及时数据具有不同密度的区域也能够很好地处理。与基于距离的方法一样，这些方法必然具有O(m^2)时间复杂度(其中m是对象个数)，虽然对于低维数据，使用专门的数据结构可以将它降低到O(mlogm)。参数选择也是困难的，虽然标准LOF算法通过观察不同的k值，然后取最大离群点得分来处理该问题。然而，仍然需要选择这些值的上下界。

**4、基于密度的离群点检测：**

一种利用聚类检测离群点的方法是丢弃原理其他簇的小簇。这种方法可以与任何聚类技术一起使用，但是需要最小簇大小和小簇与其他簇之间距离的阈值，通常，该过程可以简化为丢弃小于某个最小尺寸的所有簇。

优点与缺点：

有些聚类技术(如K均值)的时间和空间复杂度是线性或接近线性的，因而基于这种算法的离群点检测技术可能是高度有效的。此外，簇的定义通常是离群点的补，因此可能同时发现簇和离群点。**缺点方面，产生的离群点集和它们的得分可能非常依赖所用的簇的个数和数据总离群点的存在性。**例如，基于原型的算法产生的簇可能因数据中存在离群点而扭曲。聚类算法产生的簇的质量对该算法产生的离群点的质量影响非常大。每种聚类算法只适合特定的数据类型；因此，应当小心地选择聚类算法。