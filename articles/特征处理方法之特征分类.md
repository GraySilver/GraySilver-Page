# 特征分类

根据不同的分类方法，可以将特征分为:

(1)Low level特征和High level特征;

(2)稳定特征与动态特征;

(3)二值特征、连续特征、枚举特征。

1. Low level特征是较低级别的特征，主要是原始特征，不需要或者需要非常少的人工处理和干预，例如文本特征中的词向量特征，图像特征中的像素点，用户id，商品id等。
2. Low level特征一般维度比较高，不能用过于复杂的模型。
3. High level特征是经过较复杂的处理，结合部分业务逻辑或者规则、模型得到的特征，例如人工打分，模型打分等特征，可以用于较复杂的非线性模型。
4. Low level 比较针对性，覆盖面小。长尾样本的预测值主要受high level特征影响。 高频样本的预测值主要受low level特征影响。

稳定特征是变化频率(更新频率)较少的特征，例如评价平均分，团购单价格等，在较长的时间段内都不会发生变化。动态特征是更新变化比较频繁的特征，有些甚至是实时计算得到的特征，例如距离特征，2小时销量等特征。或者叫做实时特征和非实时特征。

针对两类特征的不同可以针对性地设计特征存储和更新方式，例如对于稳定特征，可以建入索引，较长时间更新一次，如果做缓存的话，缓存的时间可以较长。对于动态特征，需要实时计算或者准实时地更新数据，如果做缓存的话，缓存过期时间需要设置的较短。

二值特征主要是0/1特征，即特征只取两种值：0或者1，例如用户id特征：目前的id是否是某个特定的id，词向量特征：某个特定的词是否在文章中出现等等。连续值特征是取值为有理数的特征，特征取值个数不定，例如距离特征，特征取值为是0~正无穷。枚举值特征主要是特征有固定个数个可能值，例如今天周几，只有7个可能值：周1，周2，...，周日。

在实际的使用中，我们可能对不同类型的特征进行转换，例如将枚举特征或者连续特征处理为二值特征。枚举特征处理为二值特征技巧：将枚举特征映射为多个特征，每个特征对应一个特定枚举值，例如今天周几，可以把它转换成7个二元特征：今天是否是周一，今天是否是周二，...，今天是否是周日。连续值处理为二值特征方法：先将连续值离散化（后面会介绍如何离散化)，再将离散化后的特征切分为N个二元特征，每个特征代表是否在这个区间内。

**1.数值型**

1.1 幅度调整/归一化：sklearn会有一些函数比如preprocessing.MinMaxScaler()将幅度调整到 [0,1] 区间。

1.2 统计值：包括max, min, mean, std等。python中用pandas库序列化数据后，可以得到数据的统计值。

1.3 离散化：把连续值转成非线性数据。例如电商会有各种连续的价格表，从0.03到100元，假如以一元钱的间距分割成99个区间，用99维的向量代表每一个价格所处的区间，1.2元和1.6元的向量都是 [0,1,0,…,0]。pd.cut() 可以直接把数据分成若干段。

1.4 柱状分布：离散化后统计每个区间的个数做柱状图。

**2.类别型**

类别型一般是文本信息，比如颜色是红色、黄色还是蓝色，我们存储数据的时候就需要先处理数据。处理方法有：

2.1 one-hot编码，编码后得到哑变量。统计这个特征上有多少类，就设置几维的向量，pd.get_dummies()可以进行one-hot编码。

2.2 Hash编码成词向量：

![机器学习：聊聊机器学习中特征工程的特征处理方法](http://p3.pstatp.com/large/434500014f1e07ff996d)

3.3 Histogram映射：把每一列的特征拿出来，根据target内容做统计，把target中的每个内容对应的百分比填到对应的向量的位置。优点是把两个特征联系起来。

![机器学习：聊聊机器学习中特征工程的特征处理方法](http://p3.pstatp.com/large/433f00034f82f48333b6)

上表中，我们来统计“性别与爱好的关系”，性别有“男”“女”，爱好有三种，表示成向量[散步、足球、看电视剧]，分别计算男性和女性中每个爱好的比例得到：男[1/3, 2/3, 0]，女[0, 1/3, 2/3]。即反映了两个特征的关系。

**3.时间型**

时间型特征的用处特别大，既可以看做连续值（持续时间、间隔时间），也可以看做离散值（星期几、几月份）。数据挖掘中经常会用时间作为重要特征，比如电商可以分析节假日和购物的关系，一天中用户喜好的购物时间等。

**4.文本型**

1.词袋：文本数据预处理后，去掉停用词，剩下的词组成的list，在词库中的映射稀疏向量。Python中用CountVectorizer处理词袋．

2.把词袋中的词扩充到n-gram：n-gram代表n个词的组合。比如“我喜欢你”、“你喜欢我”这两句话如果用词袋表示的话，分词后包含相同的三个词，组成一样的向量：“我喜欢你”。显然两句话不是同一个意思，用n-gram可以解决这个问题。如果用2-gram，那么“我喜欢你”的向量中会加上“我喜欢”和“喜欢你”，“你喜欢我”的向量中会加上“你喜欢”和“喜欢我”。这样就区分开来了。

3.使用TF-IDF特征：TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。TF(t)=(词t在当前文中出现次数)/(t在全部文档中出现次数)，IDF(t) = ln(总文档数/ 含t的文档数)，TF-IDF权重 = TF(t) * IDF(t)。自然语言处理中经常会用到。

**5.统计特征**

1.加减平均值：用于观测单个值在全部数值中的平均水平位置关系；如商品价格高于平均价格多少，用户连续登陆天数超过平均多少。

2.分位线：商品属于售出商品价格的多少分位线处。

3.次序型：排在第几位。

4.比例类：占比关系；如：电商中好/坏/差的比例；

**6.组合特征**

6.1规则建立

a.if...then：标记计数。如电商类，加购物车n件，只买了一件或不买，则该用户被标记；前一天的购物车商品第二天被购买，则该用户被标记。

6.2组合特征

a.简单组合特征：

拼接型，如user_id&category(10001牛仔裤,10003女裙,10098长裤)，有则被标记，反映的是该用户是否拥有/没有该类型。

b.模型特征组合：

用GBDT产出特征组合路径；

组合特征和原始特征一起放进LR训练；

![机器学习：聊聊机器学习中特征工程的特征处理方法](http://p3.pstatp.com/large/4341000334cab69ecd4a)

![机器学习：聊聊机器学习中特征工程的特征处理方法](http://p3.pstatp.com/large/4342000326bd0d1973de)